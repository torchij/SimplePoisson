list.files()
library(shiny)
install.packages('shiny')
library(ggplot2)#
library(reshape)
# Illumina vs Ultima#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare3.txt"#
#
df <- read.delim(df_file, header=TRUE)#
df_melt <- melt(df)#
#
ggplot(subset(df_melt, tech != "NextSeq"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
library(ggplot2)#
library(reshape)
# Illumina vs Ultima#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare3.txt"#
#
df <- read.delim(df_file, header=TRUE)#
df_melt <- melt(df)#
#
ggplot(subset(df_melt, tech != "NextSeq"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(df_melt, aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
df_melt
head(df_melt)
ggplot(subset(df_melt, tech != "NextSeq" & sample != "Control-1" & sample != "Control-2"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(subset(df_melt, tech != "NextSeq" & sample != "Control-1"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(subset(df_melt, sample != "Control-1"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(subset(df_melt, sample != "Control-1" & sample != "NSC-2" & sample != "IPS-2"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# plot relative stats#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare3.txt"#
#
df <- read.delim(df_file, header=TRUE)#
#
df_melt <- melt(df)#
#
ggplot(subset(df_melt, tech != "Miseq" & tech != "ElementBio" & sample != "Control-2" & sample != "NSC-2" & sample != "IPS-1"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
library(ggplot2)#
library(reshape)
# plot relative stats#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare3.txt"#
#
df <- read.delim(df_file, header=TRUE)#
#
df_melt <- melt(df)#
#
ggplot(subset(df_melt, tech != "Miseq" & tech != "ElementBio" & sample != "Control-2" & sample != "NSC-2" & sample != "IPS-1"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
library(ggplot2)#
library(reshape)
# plot relative stats#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare4.txt"#
#
df <- read.delim(df_file, header=TRUE)#
#
df_melt <- melt(df)
# plot relative stats#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare4.txt"#
#
df <- read.delim(df_file, header=TRUE)#
#
df_melt <- melt(df)#
#
ggplot(subset(df_melt, tech != "Miseq" & tech != "ElementBio" & run != "run2", aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
)
ggplot(subset(df_melt, tech != "Miseq" & tech != "ElementBio" & run != "run2"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# plot relative stats#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/Ultima/compare4.txt"#
#
df <- read.delim(df_file, header=TRUE)#
#
df_melt <- melt(df)#
#
ggplot(subset(df_melt, tech != "Miseq" & tech != "ElementBio" & run != "run2"), aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
poisson.test(137, 24.19893)
require(graphics)
-log(dpois(0:7, lambda = 1) * gamma(1+ 0:7))
Ni <- rpois(50, lambda = 4); table(factor(Ni, 0:max(Ni)))
Ni
1 - ppois(10*(15:25), lambda = 100)
ppois(10*(15:25), lambda = 100, lower.tail = FALSE)
par(mfrow = c(2, 1))#
x <- seq(-0.01, 5, 0.01)#
plot(x, ppois(x, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")#
plot(x, pbinom(x, 100, 0.01), type = "s", ylab = "F(x)",#
     main = "Binomial(100, 0.01) CDF")
?ppois
ppois(4, 1)
ppois(0:100, 1)
dpois(3, 1)
x.poi<-rpois(n=200,lambda=2.5)
hist(x.poi,main="Poisson distribution")
lambda.est <- mean(x.poi)
table(x.poi)
(tab.os<-table(x.poi))
tab.os
freq.os<-vector()#
for(i in 1: length(tab.os)) freq.os[i]<-tab.os[[i]]
freq.ex<-(dpois(0:max(x.poi),lambda=lambda.est)*200)
x.poi
mean(x.poi)
(tab.os<-table(x.poi))
for(i in 1: length(tab.os)) freq.os[i]<-tab.os[[i]]
freq.ex<-(dpois(0:max(x.poi),lambda=lambda.est)*200)
acc <- mean(abs(freq.os-trunc(freq.ex))) ## absolute goodness of fit index acc#
acc/mean(freq.os)*100 ## relative (percent) goodness of fit index
h <- hist(x.poi ,breaks=length(tab.os))#
xhist <- c(min(h$breaks),h$breaks)#
yhist <- c(0,h$density,0)#
xfit <- min(x.poi):max(x.poi)#
yfit <- dpois(xfit,lambda=lambda.est)#
plot(xhist,yhist,type="s",ylim=c(0,max(yhist,yfit)), main="Poison density and histogram")#
lines(xfit,yfit, col="red")
library(vcd) ## loading vcd package
install.packages("vcd")
library(vcd) ## loading vcd package
x.poi
gf <- goodfit(x.poi,type= "poisson",method= "MinChisq")
summary(gf)
plot(gf,main="Count data vs Poisson distribution")
df_file <- "/Users/jtorchia/OneDrive - ERS/hcc1187/hcc1187_filtered.nsorted.tloc.bam.coverage"#
#
df <- read.delim(df_file, header=FALSE)
head(df)
gf <- goodfit(df$V7, type="poisson",method="MinChisq")
plot(gf,main="Count data vs Poisson distribution")
?goodfit
dummy <- rnbinom(200, size = 1.5, prob = 0.8)
gf <- goodfit(dummy, type = "nbinomial", method = "MinChisq")
dummy
gf <- goodfit(df$V7, type="poisson",method="MinChisq")
dummy <- rnbinom(200, size = 1.5, prob = 0.8)#
gf <- goodfit(dummy, type = "nbinomial", method = "MinChisq")#
summary(gf)#
plot(gf)
gf
data("HorseKicks")#
HK.fit <- goodfit(HorseKicks)#
summary(HK.fit)#
plot(HK.fit)
gf <- goodfit(df$V7, type="poisson",method="MinChisq")#
summary(gf)#
plot(gf)
df$V7
# goodness of fit test#
gf <- goodfit(round(df$V7), type="poisson",method="MinChisq")#
summary(gf)#
plot(gf)
plot(df$V7)
plot(dummy)
plot(round(df$V7))
plot(hist(round(df$V7)))
library(cn.mops)
library(rtracklayer)#
library(seqbias)#
library(cn.mops)#
#library(vcd)#
#
# inputs#
hg38_bed_file <- "/Users/jtorchia/OneDrive - ERS/hcc1187/hg38.canonical.chrom.sizes.0based.bed"#
targ_bed_file <- "/Users/jtorchia/OneDrive - ERS/hcc1187/SV_probes_v.b.0.1.annotated.bed"#
bam_file <- "/Users/jtorchia/OneDrive - ERS/hcc1187/test.bam"#
#
#hg38_bed_file <- "/mnt/ebs/jon/hcc1187/hg38.canonical.chrom.sizes.0based.bed"#
#targ_bed_file <- "/mnt/ebs/jon/hcc1187/SV_probes_v.b.0.1.annotated.bed"#
#bam_file <- "/mnt/ebs/jon/hcc1187/downsample/bam/hcc1187_0.0625.bam"#
#
###################################################
##### Step 1: Estimate lambda from bam file) ######
###################################################
#
# read in hg38 intervals (canonical)#
gr_hg38 <- import(hg38_bed_file)#
#
# get read counts from bam file#
gr1 <- getReadCountsFromBAM(bam_file, sampleNames="testSample", WL=1000, parallel=2)
gr1
gr1$testSample
?sample
gr1
gr1_samp <- sample(gr1, size=100)
gr1_samp <- sample(gr1$testSample, size=100)
gr1_samp
mean(gr1_samp)
sample(gr1$testSample, size=100)
# set sampling interval length, number of intervals, and replicate number#
 num_interval <- 1000#
 num_basepair <- 1000#
num_replicate <- 10#
interval_size <- num_basepair * num_interval#
#
### testing#
# sample n rows from granges ojbect#
gr1_samp <- replicate(num_replicate, sample(gr1$testSample, size=100))
gr1_samp
gr1_samp <- replicate(num_replicate, sum(sample(gr1$testSample, size=100)))
gr1_samp
mean(gr1_samp)
mean(gr1_samp) / interval_size
# sample read counts#
counts_sum <- replicate(num_replicate, sum(subsetByOverlaps(gr1, random.intervals(gr_hg38, n=num_interval, ms=num_basepair))$testSample))#
#
# estimate lambda#
counts_avg <- mean(counts_sum)#
counts_std <- sd(counts_sum)#
lambda <- counts_avg / interval_size#
lambda
install.packages("remotes")
remotes::install_github("giocomai/ganttrify")
library(ganttrify)
test_36 <- ganttrify::test_project#
test_36[11,4] <- 36#
#
ganttrify(project = test_36,#
          project_start_date = "2021-04", #
          month_breaks = 3,#
          show_vertical_lines = FALSE)
ganttrify(project = ganttrify::test_project,#
          hide_wp = TRUE,#
          font_family = "Roboto Condensed")
test_36 <- ganttrify::test_project#
test_36[11,4] <- 36#
#
ganttrify(project = test_36,#
          project_start_date = "2021-04", #
          month_breaks = 3,#
          show_vertical_lines = FALSE)
getwd()
df_file <- "/Users/jtorchia/Desktop/gantt_example.txt"#
#
df <- read.delim(df_file)
df
library(tidyrverse)
ganttrify(project=df)
ganttrify(project=df,#
          project_start_date = "2021-03",#
          font_family = "Roboto Condensed")
ganttrify::test_project
install.packages('tidyrverse')
install.packages('tidyverse')
library(tidyverse)
tb <- as_tibble(read.delim(df_file))
tb
ganttrify::test_project
ganttrify(project=tb,#
          project_start_date = "2022-08",#
          font_family = "Roboto Condensed")
ganttrify(project = ganttrify::test_project,#
          spots = ganttrify::test_spots,#
          project_start_date = "2021-03",#
          size_text_relative = 1.2, #
          mark_quarters = TRUE,#
          font_family = "Roboto Condensed")
ganttrify(project = ganttrify::test_project,#
          project_start_date = "2021-03",#
          font_family = "Roboto Condensed")
library("ganttrify")#
#
ganttrify(project = ganttrify::test_project,#
          project_start_date = "2021-03",#
          font_family = "Roboto Condensed")
ganttrify(project = ganttrify::test_project,#
          project_start_date = "2021-03",#
          font_family = "Roboto Condensed")
library(ggplot2)#
library(reshape)
# plot relative stats#
df_file <- "/Users/jtorchia/OneDrive - ERS/tech-comparison/V1_vs_V2/compare.txt"#
#
df <- read.delim(df_file, header=TRUE)#
#
df_melt <- melt(df)#
#
ggplot(df_melt, aes(fill=tech, y=value, x=variable)) + #
    geom_bar(position="dodge", stat="identity") +#
    facet_wrap(~sample) +#
    theme_bw() +#
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
df
colnames(df)
a <- c(1,2,3,1,2,1,1,3,1,2,3,5)
a
MASS::fitdistr(a,"Poisson")
mean(a)
plot(a)
?ppois
ppois(3.2, 5)
ppois(3, 5)
args = commandArgs(trailingOnly=TRUE)#
#
if (length(args) != 3){#
    cat("Usage: get_ppois_from_bam.r bam_file bed_file cpu_number\n")#
    quit(save="no")#
} else {#
    library(rtracklayer)#
    library(data.table)#
    library(seqbias)#
    library(cn.mops)#
    library(vcd)#
}
df <- data.frame(x = 1:4, y = 5:8, z = 10:13)
df
apply(df, 1, sum)
apply(df, 2, sum)
apply(df, 1, sum)
apply(df[1:2,], 1, sum)
apply(df, 2, sum)
apply(df, 1, sum)
apply(df, c(1,2), sum)
array(data = 1:18, dim = c(3, 2, 3))
m1 <- matrix(C<-(1:10),nrow=5, ncol=6)#
m1#
a_m1 <- apply(m1, 2, sum)#
a_m1
a_m1
m1
movies <- c("SPYDERMAN","BATMAN","VERTIGO","CHINATOWN")
movies
movies_lower <-lapply(movies, tolower)
movies_lower
str(movies_lower)
unlist(movies_lower)
cars
dt <- cars#
lmn_cars <- lapply(dt, min)#
smn_cars <- sapply(dt, min)#
lmn_cars
lmn_cars
smn_cars
head(cars)
Age<-c(56,34,67,33,25,28)#
Weight<-c(78,67,56,44,56,89)#
Height<-c(165, 171,167,167,166,181)#
BMI_df<-data.frame(Age,Weight,Height)#
BMI_df
BMI_df
apply(BMI_df,1,sum)
BMI_df$stuff <- apply(BMI_df,1,sum)
apply(BMI_df,1,sum)
BMI_df
BMI_df<-data.frame(Age,Weight,Height)
BMI_df
library(rtracklayer)#
    library(data.table)#
    #library(seqbias)#
    #library(cn.mops)#
    #library(vcd)#
    library(GenomicAlignments)
# inputs test 3#
setwd("/Users/jtorchia/git/torchij/SimplePoisson/")#
bam_file <- "hcc1187_filtered.sorted.tloc.bam"     # input bam file (**NB** PREFILTERED TRANS-ONLY BAM)#
#bed_file <- "SV_probes_v.b.2.1.bed"                 # target probe bed file#
bed_file <- "regions_v.b.2.1.bed"#
con_file <- "cont.bed"                              # control probe bed file#
cpu_numb <- 2                                       # parallelize the huge bam counts step#
#
# sampling inputs#
num_reps <- 1000#
#
# set output name#
samp <- gsub("\\.bam", "", basename(bam_file))#
#
poissonness_test <- function(counts) {#
#
    # based on Hoaglin, 1980: “A poissonness plot”#
    n=length(counts)#
    x=table(counts)#
    k=as.numeric(names(x))#
    f=c(log(x) + lfactorial(k))#
    r=n*(1-cor(k,log(x)+lfactorial(k))^2)#
    ppois_test <- list(k, f, r)#
    return(ppois_test)#
#
}#
#
###################################################
##### Step 1: Calculate signal from bam file  #####
###################################################
#
# read in bam file#
galp <- readGAlignmentPairs(bam_file, use.names=TRUE, strandMode=1)#
#
# get trans reads#
galp <- galp[seqnames(first(galp)) != seqnames(second(galp))]#
#
# read in bed file with probes#
bed <- read.table(bed_file, header=FALSE)#
#colnames(bed) <- c("chrom", "start", "end", "probeLen", "strand", "tlocID", "probeID") # for probe file#
colnames(bed) <- c("chrom", "start", "end", "tlocID", "score", "strand") # for region file#
#
# aggregate concatenate to get chromosome pairs#
pre <- unique(bed[c(1:4)])#
key <- aggregate(cbind(chrom, start, end) ~ tlocID, data=unique(bed[c(1:4)]), FUN = c)#
#
# for each row, do stuff#
padding=100000#
result <- data.frame(matrix(ncol = 4, nrow = 0))#
resNam <- c("tlocID", "chrA", "chrB", "support")#
colnames(result) <- resNam#
for (row in 1:nrow(key)) {#
#
    tloc <- key[row, "tlocID"]#
    chrA <- key[row, "chrom"][1]#
    chrB <- key[row, "chrom"][2]#
    staA <- as.numeric(key[row, "start"][1]) - padding#
    staB <- as.numeric(key[row, "start"][2]) - padding#
    endA <- as.numeric(key[row, "end"][1]) + padding#
    endB <- as.numeric(key[row, "end"][2]) + padding#
    a <- length(galp[ (seqnames(first(galp)) == chrA & (start(first(galp)) > staA & start(first(galp)) < endA)) & seqnames(second(galp)) == chrB ])#
    b <- length(galp[ (seqnames(first(galp)) == chrB & (start(first(galp)) > staB & start(first(galp)) < endB)) & seqnames(second(galp)) == chrA ])#
    c <- length(galp[ (seqnames(second(galp)) == chrA & (start(second(galp)) > staA & start(second(galp)) < endA)) & seqnames(first(galp)) == chrB ])#
    d <- length(galp[ (seqnames(second(galp)) == chrB & (start(second(galp)) > staB & start(second(galp)) < endB)) & seqnames(first(galp)) == chrA ])#
    support <- a + b + c + d#
    #support <- length(galp[ (seqnames(first(galp)) == chrA & seqnames(second(galp)) == chrB) | (seqnames(first(galp)) == chrB & seqnames(second(galp)) == chrA) ])#
    newRow <- data.frame(tlocID=tloc, chrA=chrA, chrB=chrB, support=support)#
    result <- rbind(result, newRow)#
#
}
result
# we use bedtools to get the counts per probe interval#
# side note: there may be an r-native way to do this,#
# but bedtools does it so efficiently...#
cmd <- paste0("bedtools multicov -bams ", bam_file, " -bed ", con_file)#
#
# fread has a nice method to take output of system command#
df_con <- fread(cmd=cmd)
df_con
colnames(df_con) <- c("chrom", "start", "end", "probe", "score", "strand", "counts")
df_con
# sample n rows from control (17 is the number of probes per tloc)#
counts_sum <- replicate(num_reps, sum(df_con[sample(nrow(df_con), 34), ]$counts))#
lambda <- median(counts_sum)
lambda
lambda <- median(counts_sum) + 1
lambda
bg <- poissonness_test(counts_sum)#
k=bg[[1]]; f=bg[[2]]; r=bg[[3]]#
fg <- poissonness_test(counts_sum)#
k2=fg[[1]]; f2=fg[[2]]; r2=fg[[3]]
plot(k, f, col="black", main=paste0("poissonness test (bg) - ", as.character(signif(r, 4))))#
    points(k2, f2, col="red")
hist(counts_sum, breaks=50, main="background counts distribution")
result
ppois(q=df_agg$support, lambda=lambda, lower.tail=FALSE, log=FALSE)
ppois(q=result$support, lambda=lambda, lower.tail=FALSE, log=FALSE)
result$pvalue <- ppois(q=result$support, lambda=lambda, lower.tail=FALSE, log=FALSE)
result
